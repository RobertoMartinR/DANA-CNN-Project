{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "em19T_Lmliro",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "912a2a6a-5bf5-4bac-cafd-4e38125d3137"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSe pretende realizar un modelo que pueda predecir posibles inundaciones a través de imágenes de un mismo río en diferentes estados para intentar prevenir\\nsucesos como el de la DANA de Valencia del 29/10/2024 y que el propio modelo sea capaz de avisar a la población en caso de una posible riada ya que preferimos un Falso Positivo antes de un Falso Negativo\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "Se pretende realizar un modelo que pueda predecir posibles inundaciones a través de imágenes de un mismo río en diferentes estados para intentar prevenir\n",
        "sucesos como el de la DANA de Valencia del 29/10/2024 y que el propio modelo sea capaz de avisar a la población en caso de una posible riada ya que preferimos un Falso Positivo antes\n",
        "de un Falso Negativo.\n",
        "\n",
        "Los significados para cada letra son los siguientes: A -> Alto nivel del agua, B -> Nivel de agua creciendo gradualmente, C -> Nivel normal de agua.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lo primero que vamos a hacer es montar el Drive ya que tenemos todas las imágenes subidas en nuestra carpeta de Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAWBcLX5D_vh",
        "outputId": "0b132337-d0dc-49c9-bbf3-2d6bdcedd409"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A continuación vamos a importar las librerias que vamos a utilizar a lo largo del proyecto\n",
        "!pip install tensorflow keras\n",
        "import tensorflow as tf\n",
        "print(\"Versión de TensorFlow:\", tf.__version__)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.layers import *\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NteEpF3amJDj",
        "outputId": "7b00deb6-a6b8-4135-e155-29ce2192ebac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Versión de TensorFlow: 2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A continuación importamos los datos de train y test\n",
        "\n",
        "train_data_dir = (\"/content/drive/MyDrive/RAIN_DATA/train\")\n",
        "test_data_dir = (\"/content/drive/MyDrive/RAIN_DATA/test\")"
      ],
      "metadata": {
        "id": "KwI92_2hmi1S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Si ejecutamos las siguientes celdas de código va a saltar un mensaje indicando que hay 0 Imágenes ya que keras no es capaz de encontrar las imágenes porque están todas en la misma carpeta,\n",
        "por eso voy a ejecutar este script y que las imágenes queden ordenadas en 3 carpetas llamadas A, B y C almacenando cada imágen en su carpeta correspondiente.\n",
        "\"\"\"\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Ruta a los directorios\n",
        "train_dir = \"/content/drive/MyDrive/RAIN_DATA/train\"\n",
        "test_dir = \"/content/drive/MyDrive/RAIN_DATA/test\"\n",
        "\n",
        "# Crear subcarpetas si no existen\n",
        "for folder in ['A', 'B', 'C']:\n",
        "    os.makedirs(os.path.join(train_dir, folder), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, folder), exist_ok=True)\n",
        "\n",
        "# Función para mover imágenes a su subcarpeta\n",
        "def organizar_imagenes(base_dir):\n",
        "    for file in os.listdir(base_dir):\n",
        "        file_path = os.path.join(base_dir, file)\n",
        "\n",
        "        # Asegurarse de que sea un archivo y no una carpeta\n",
        "        if os.path.isfile(file_path):\n",
        "            if file.startswith('A'):\n",
        "                shutil.move(file_path, os.path.join(base_dir, 'A', file))\n",
        "            elif file.startswith('B'):\n",
        "                shutil.move(file_path, os.path.join(base_dir, 'B', file))\n",
        "            elif file.startswith('C'):\n",
        "                shutil.move(file_path, os.path.join(base_dir, 'C', file))\n",
        "\n",
        "# Organizar imágenes en train y test\n",
        "organizar_imagenes(train_dir)\n",
        "organizar_imagenes(test_dir)\n",
        "\n",
        "print(\"Organización completada correctamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CPrnbRLGrIz",
        "outputId": "a4a24df9-54bb-4259-b81c-8fa30634e1dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Organización completada correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Antes de entrenar nuestro modelo con estos datos vamos a realizar Data Augmentation para tener más cantidad de imágenes con las que entrenar, así es más probable obtener mejores resultados\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,         # Normalización de píxeles (0 a 1)\n",
        "    rotation_range=30,       # Rotación aleatoria hasta 30 grados\n",
        "    width_shift_range=0.2,   # Desplazamiento horizontal hasta 20%\n",
        "    height_shift_range=0.2,  # Desplazamiento vertical hasta 20%\n",
        "    shear_range=0.2,         # Inclinación de la imagen\n",
        "    zoom_range=0.2,          # Zoom aleatorio del 20%\n",
        "    horizontal_flip=True,    # Inversión horizontal\n",
        "    fill_mode='nearest'      # Relleno de píxeles vacíos\n",
        ")\n",
        "\n",
        "# Para test no vamos a aplicar DataAugmentation ya que lo único que queremos es comprobar si el modelo puede predecir correctamente\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)"
      ],
      "metadata": {
        "id": "-s9JmFUOpieg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A continuación vamos a cargar las imágenes tanto de train como de test\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(\"224\", \"224\"),  # Tamaño de las imágenes\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(\"224\", \"224\"),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "GLUGc7qDp9db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e75197ca-fdea-476c-a12d-b453503cf1ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4800 images belonging to 3 classes.\n",
            "Found 1200 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Una vez ya tenemos las imágenes identificadas vamos a crear el modelo con el que vamos a trabajar\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),  # Reduce overfitting\n",
        "    Dense(3, activation='softmax')  # 3 clases: A, B, C\n",
        "])\n",
        "\n",
        "# Compilamos el modelo\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Resumen de la arquitectura\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "WbMx-03trlcS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}